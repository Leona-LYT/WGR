{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "29f863c7-52e9-4f51-ae00-bc3c97f2ba53",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nincase the above code does not work, you can use the absolute path instead\\nsys.path.append(r\".\")\\n'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import sys\n",
    "import os\n",
    "current_dir = os.getcwd()  #use to import the defined functions\n",
    "parent_dir = os.path.dirname(current_dir) \n",
    "sys.path.append(parent_dir)  \n",
    "\n",
    "\"\"\"\n",
    "incase the above code does not work, you can use the absolute path instead\n",
    "sys.path.append(r\".\\\")\n",
    "\"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "09f578f4-d40c-4e9c-b234-ea17249bff03",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "import torch.optim as optim\n",
    "from torch.optim.lr_scheduler import ReduceLROnPlateau "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6bd617ea-5efb-4a88-98f4-fd3e086ed102",
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.basic_utils import setup_seed\n",
    "from data.SimulationData import DataGenerator \n",
    "from utils.training_utils import train_WGR_fnn\n",
    "from utils.evaluation_utils import L1L2_MSE_mean_sd_G, MSE_quantile_G_uniY\n",
    "from models.generator import generator_fnn\n",
    "from models.discriminator import discriminator_fnn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e82f422a-70a8-4191-b99d-16612d3dbef0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Namespace(Xdim=100, Ydim=1, model='M1', noise_dim=5, noise_dist='gaussian', train=5000, val=1000, test=1000, train_batch=128, val_batch=100, test_batch=100, epochs=100, reps=100)\n"
     ]
    }
   ],
   "source": [
    "import argparse\n",
    "\n",
    "if 'ipykernel_launcher.py' in sys.argv[0]:  #if not work in jupyter, you can delete this part\n",
    "    import sys\n",
    "    sys.argv = [sys.argv[0]] \n",
    "\n",
    "\n",
    "parser = argparse.ArgumentParser(description='Implementation of WGR for M1')\n",
    "\n",
    "parser.add_argument('--Xdim', default=100, type=int, help='dimensionality of X')\n",
    "parser.add_argument('--Ydim', default=1, type=int, help='dimensionality of Y')\n",
    "parser.add_argument('--model', default='M1', type=str, help='model')\n",
    "\n",
    "parser.add_argument('--noise_dim', default=5, type=int, help='dimensionality of noise vector')\n",
    "parser.add_argument('--noise_dist', default='gaussian', type=str, help='distribution of noise vector')\n",
    "\n",
    "parser.add_argument('--train', default=5000, type=int, help='size of train dataset')\n",
    "parser.add_argument('--val', default=1000, type=int, help='size of validation dataset')\n",
    "parser.add_argument('--test', default=1000, type=int, help='size of test dataset')\n",
    "\n",
    "parser.add_argument('--train_batch', default=128, type=int, metavar='BS', help='batch size while training')\n",
    "parser.add_argument('--val_batch', default=100, type=int, metavar='BS', help='batch size while validation')\n",
    "parser.add_argument('--test_batch', default=100, type=int, metavar='BS', help='batch size while testing')\n",
    "parser.add_argument('--epochs', default=100, type=int, help='number of epochs to train')\n",
    "parser.add_argument('--reps', default=100, type=int, help='number of replications')\n",
    "\n",
    "args = parser.parse_args()\n",
    "\n",
    "print(args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a1c1b44a-0c6c-478a-b807-e5e1da20a1ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set seed \n",
    "setup_seed(1235)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "177a8bd5-74a6-4ffe-ab47-e2e7cc821c35",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate data from M1\n",
    "data_gen = DataGenerator(args)\n",
    "DATA = data_gen.generate_data(args.model)\n",
    "train_X, train_Y = DATA['train_X'], DATA['train_Y']\n",
    "val_X, val_Y = DATA['val_X'], DATA['val_Y']\n",
    "test_X, test_Y = DATA['test_X'], DATA['test_Y']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "de288fbd-c582-4ad8-b10d-59b3d145e2a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create TensorDatasets and initialize a DataLoaders\n",
    "train_dataset = TensorDataset( train_X.float(), train_Y.float() )\n",
    "loader_train = DataLoader(train_dataset , batch_size=args.train_batch, shuffle=True)\n",
    "\n",
    "val_dataset = TensorDataset( val_X.float(), val_Y.float() )\n",
    "loader_val = DataLoader(val_dataset , batch_size=args.val_batch, shuffle=True)\n",
    "\n",
    "test_dataset = TensorDataset( test_X.float(), test_Y.float() )\n",
    "loader_test  = DataLoader(test_dataset , batch_size=args.test_batch, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "20bb4d11-47ef-4e17-9852-27ea723f271c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define generator network and discriminator network\n",
    "G_net = generator_fnn(Xdim=args.Xdim, Ydim=args.Ydim, noise_dim=args.noise_dim, hidden_dims = [64, 32])\n",
    "D_net = discriminator_fnn(input_dim=args.Xdim+args.Ydim, hidden_dims = [64, 32])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "08ccda7e-1d68-4ff1-9e4b-d5caa66dcf81",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize RMSprop optimizers\n",
    "D_solver = optim.RMSprop(D_net.parameters(),lr = 0.001)\n",
    "G_solver = optim.RMSprop(G_net.parameters(),lr = 0.001)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e92b5e23-d404-4c3e-b5ac-fde5ba358c24",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean L1 Loss: 3.254895, Mean L2 Loss: 18.813904\n",
      "Epoch 0 - D Loss: 0.8040, G Loss: 1.6796\n",
      "Epoch 1 - D Loss: 0.1826, G Loss: 1.9566\n",
      "Epoch 2 - D Loss: 0.0151, G Loss: 2.1025\n",
      "Epoch 3 - D Loss: 0.0942, G Loss: 2.1219\n",
      "Epoch 4 - D Loss: 0.2083, G Loss: 2.3719\n",
      "Epoch 5 - D Loss: 0.1377, G Loss: 3.0096\n",
      "Epoch 6 - D Loss: 0.0252, G Loss: 3.5932\n",
      "Epoch 7 - D Loss: 0.0213, G Loss: 3.7865\n",
      "Epoch 8 - D Loss: 0.0141, G Loss: 3.7014\n",
      "Epoch 9 - D Loss: 0.0015, G Loss: 3.5755\n",
      "Epoch 10 - D Loss: -0.0007, G Loss: 3.4309\n",
      "Epoch 11 - D Loss: -0.0072, G Loss: 3.4327\n",
      "Epoch 12 - D Loss: -0.0107, G Loss: 3.4724\n",
      "Epoch 13 - D Loss: -0.0168, G Loss: 3.4260\n",
      "Epoch 14 - D Loss: -0.0194, G Loss: 3.3356\n",
      "Epoch 15 - D Loss: -0.0170, G Loss: 3.2924\n",
      "Epoch 16 - D Loss: -0.0239, G Loss: 3.2110\n",
      "Epoch 17 - D Loss: -0.0221, G Loss: 3.1438\n",
      "Epoch 18 - D Loss: -0.0224, G Loss: 3.0853\n",
      "Epoch 19 - D Loss: -0.0259, G Loss: 3.0653\n",
      "Epoch 20 - D Loss: -0.0229, G Loss: 2.9922\n",
      "Epoch 21 - D Loss: -0.0192, G Loss: 2.9663\n",
      "Epoch 22 - D Loss: -0.0216, G Loss: 3.0025\n",
      "Epoch 23 - D Loss: -0.0215, G Loss: 2.9544\n",
      "Epoch 24 - D Loss: -0.0290, G Loss: 2.8705\n",
      "Mean L1 Loss: 1.740025, Mean L2 Loss: 5.977261\n",
      "Epoch 25, Iter 1000, D Loss: -0.0238, G Loss: 2.8344, L1: 1.7400, L2: 5.9773\n",
      "Saved best model with L2: 5.9773\n",
      "Epoch 25 - D Loss: -0.0257, G Loss: 2.8692\n",
      "Mean L1 Loss: 1.755098, Mean L2 Loss: 6.123224\n",
      "Epoch 26, Iter 1050, D Loss: -0.0253, G Loss: 2.8564, L1: 1.7551, L2: 6.1232\n",
      "Epoch 26 - D Loss: -0.0244, G Loss: 2.8514\n",
      "Epoch 27 - D Loss: -0.0283, G Loss: 2.7803\n",
      "Mean L1 Loss: 1.810330, Mean L2 Loss: 6.296041\n",
      "Epoch 28, Iter 1100, D Loss: -0.0302, G Loss: 2.7203, L1: 1.8103, L2: 6.2960\n",
      "Epoch 28 - D Loss: -0.0263, G Loss: 2.7467\n",
      "Mean L1 Loss: 1.849805, Mean L2 Loss: 6.455241\n",
      "Epoch 29, Iter 1150, D Loss: -0.0337, G Loss: 2.7047, L1: 1.8498, L2: 6.4552\n",
      "Epoch 29 - D Loss: -0.0255, G Loss: 2.7164\n",
      "Mean L1 Loss: 1.836429, Mean L2 Loss: 6.430646\n",
      "Epoch 30, Iter 1200, D Loss: -0.0274, G Loss: 2.7120, L1: 1.8364, L2: 6.4306\n",
      "Epoch 30 - D Loss: -0.0260, G Loss: 2.7267\n",
      "Epoch 31 - D Loss: -0.0260, G Loss: 2.7402\n",
      "Mean L1 Loss: 1.830454, Mean L2 Loss: 6.455257\n",
      "Epoch 32, Iter 1250, D Loss: -0.0336, G Loss: 2.7148, L1: 1.8305, L2: 6.4553\n",
      "Epoch 32 - D Loss: -0.0240, G Loss: 2.6733\n",
      "Mean L1 Loss: 1.914051, Mean L2 Loss: 6.812997\n",
      "Epoch 33, Iter 1300, D Loss: -0.0224, G Loss: 2.6960, L1: 1.9141, L2: 6.8130\n",
      "Epoch 33 - D Loss: -0.0211, G Loss: 2.7098\n",
      "Mean L1 Loss: 1.920480, Mean L2 Loss: 6.886600\n",
      "Epoch 34, Iter 1350, D Loss: -0.0227, G Loss: 2.6629, L1: 1.9205, L2: 6.8866\n",
      "Epoch 34 - D Loss: -0.0226, G Loss: 2.6673\n",
      "Mean L1 Loss: 1.907783, Mean L2 Loss: 6.838295\n",
      "Epoch 35, Iter 1400, D Loss: -0.0236, G Loss: 2.6691, L1: 1.9078, L2: 6.8383\n",
      "Epoch 35 - D Loss: -0.0232, G Loss: 2.6722\n",
      "Epoch 36 - D Loss: -0.0218, G Loss: 2.6925\n",
      "Mean L1 Loss: 1.948136, Mean L2 Loss: 7.094216\n",
      "Epoch 37, Iter 1450, D Loss: -0.0239, G Loss: 2.6073, L1: 1.9481, L2: 7.0942\n",
      "Epoch 37 - D Loss: -0.0261, G Loss: 2.6501\n",
      "Mean L1 Loss: 1.975875, Mean L2 Loss: 7.203879\n",
      "Epoch 38, Iter 1500, D Loss: -0.0216, G Loss: 2.6542, L1: 1.9759, L2: 7.2039\n",
      "Epoch 38 - D Loss: -0.0234, G Loss: 2.6292\n",
      "Mean L1 Loss: 1.957446, Mean L2 Loss: 7.119015\n",
      "Epoch 39, Iter 1550, D Loss: -0.0252, G Loss: 2.6208, L1: 1.9574, L2: 7.1190\n",
      "Epoch 39 - D Loss: -0.0234, G Loss: 2.6292\n",
      "Epoch 40 - D Loss: -0.0243, G Loss: 2.6361\n",
      "Mean L1 Loss: 2.001662, Mean L2 Loss: 7.414987\n",
      "Epoch 41, Iter 1600, D Loss: -0.0134, G Loss: 2.7470, L1: 2.0017, L2: 7.4150\n",
      "Epoch 41 - D Loss: -0.0205, G Loss: 2.6492\n",
      "Mean L1 Loss: 2.036742, Mean L2 Loss: 7.582751\n",
      "Epoch 42, Iter 1650, D Loss: -0.0250, G Loss: 2.6262, L1: 2.0367, L2: 7.5828\n",
      "Epoch 42 - D Loss: -0.0228, G Loss: 2.6341\n",
      "Mean L1 Loss: 2.060951, Mean L2 Loss: 7.710231\n",
      "Epoch 43, Iter 1700, D Loss: -0.0211, G Loss: 2.6349, L1: 2.0610, L2: 7.7102\n",
      "Epoch 43 - D Loss: -0.0213, G Loss: 2.6466\n",
      "Mean L1 Loss: 2.089061, Mean L2 Loss: 7.893991\n",
      "Epoch 44, Iter 1750, D Loss: -0.0181, G Loss: 2.6517, L1: 2.0891, L2: 7.8940\n",
      "Epoch 44 - D Loss: -0.0183, G Loss: 2.6524\n",
      "Epoch 45 - D Loss: -0.0166, G Loss: 2.6523\n",
      "Mean L1 Loss: 2.047668, Mean L2 Loss: 7.680988\n",
      "Epoch 46, Iter 1800, D Loss: -0.0125, G Loss: 2.6311, L1: 2.0477, L2: 7.6810\n",
      "Epoch 46 - D Loss: -0.0221, G Loss: 2.6297\n",
      "Mean L1 Loss: 2.049417, Mean L2 Loss: 7.705041\n",
      "Epoch 47, Iter 1850, D Loss: -0.0180, G Loss: 2.6485, L1: 2.0494, L2: 7.7050\n",
      "Epoch 47 - D Loss: -0.0202, G Loss: 2.6548\n",
      "Mean L1 Loss: 2.061617, Mean L2 Loss: 7.781678\n",
      "Epoch 48, Iter 1900, D Loss: -0.0187, G Loss: 2.6622, L1: 2.0616, L2: 7.7817\n",
      "Epoch 48 - D Loss: -0.0181, G Loss: 2.6513\n",
      "Mean L1 Loss: 2.134965, Mean L2 Loss: 8.226306\n",
      "Epoch 49, Iter 1950, D Loss: -0.0164, G Loss: 2.6399, L1: 2.1350, L2: 8.2263\n",
      "Epoch 49 - D Loss: -0.0164, G Loss: 2.6399\n",
      "Epoch 50 - D Loss: -0.0150, G Loss: 2.6809\n",
      "Mean L1 Loss: 2.099231, Mean L2 Loss: 8.096547\n",
      "Epoch 51, Iter 2000, D Loss: -0.0132, G Loss: 2.6548, L1: 2.0992, L2: 8.0965\n",
      "Epoch 51 - D Loss: -0.0169, G Loss: 2.6515\n",
      "Mean L1 Loss: 2.131200, Mean L2 Loss: 8.248693\n",
      "Epoch 52, Iter 2050, D Loss: -0.0129, G Loss: 2.6547, L1: 2.1312, L2: 8.2487\n",
      "Epoch 52 - D Loss: -0.0151, G Loss: 2.6646\n",
      "Mean L1 Loss: 2.114406, Mean L2 Loss: 8.151627\n",
      "Epoch 53, Iter 2100, D Loss: -0.0168, G Loss: 2.7022, L1: 2.1144, L2: 8.1516\n",
      "Epoch 53 - D Loss: -0.0155, G Loss: 2.6986\n",
      "Epoch 54 - D Loss: -0.0121, G Loss: 2.7140\n",
      "Mean L1 Loss: 2.122278, Mean L2 Loss: 8.254061\n",
      "Epoch 55, Iter 2150, D Loss: -0.0165, G Loss: 2.6751, L1: 2.1223, L2: 8.2541\n",
      "Epoch 55 - D Loss: -0.0150, G Loss: 2.7138\n",
      "Mean L1 Loss: 2.142222, Mean L2 Loss: 8.297170\n",
      "Epoch 56, Iter 2200, D Loss: -0.0080, G Loss: 2.7211, L1: 2.1422, L2: 8.2972\n",
      "Epoch 56 - D Loss: -0.0134, G Loss: 2.7167\n",
      "Mean L1 Loss: 2.150719, Mean L2 Loss: 8.350959\n",
      "Epoch 57, Iter 2250, D Loss: -0.0119, G Loss: 2.6980, L1: 2.1507, L2: 8.3510\n",
      "Epoch 57 - D Loss: -0.0119, G Loss: 2.7012\n",
      "Mean L1 Loss: 2.155165, Mean L2 Loss: 8.415070\n",
      "Epoch 58, Iter 2300, D Loss: -0.0151, G Loss: 2.7103, L1: 2.1552, L2: 8.4151\n",
      "Epoch 58 - D Loss: -0.0146, G Loss: 2.7111\n",
      "Epoch 59 - D Loss: -0.0105, G Loss: 2.7287\n",
      "Mean L1 Loss: 2.141182, Mean L2 Loss: 8.300102\n",
      "Epoch 60, Iter 2350, D Loss: -0.0109, G Loss: 2.7229, L1: 2.1412, L2: 8.3001\n",
      "Epoch 60 - D Loss: -0.0119, G Loss: 2.7109\n",
      "Mean L1 Loss: 2.182477, Mean L2 Loss: 8.642542\n",
      "Epoch 61, Iter 2400, D Loss: -0.0140, G Loss: 2.6792, L1: 2.1825, L2: 8.6425\n",
      "Epoch 61 - D Loss: -0.0141, G Loss: 2.6988\n",
      "Mean L1 Loss: 2.219822, Mean L2 Loss: 8.876571\n",
      "Epoch 62, Iter 2450, D Loss: -0.0106, G Loss: 2.6968, L1: 2.2198, L2: 8.8766\n",
      "Epoch 62 - D Loss: -0.0100, G Loss: 2.7027\n",
      "Epoch 63 - D Loss: -0.0081, G Loss: 2.7084\n",
      "Mean L1 Loss: 2.181125, Mean L2 Loss: 8.607499\n",
      "Epoch 64, Iter 2500, D Loss: -0.0042, G Loss: 2.6713, L1: 2.1811, L2: 8.6075\n",
      "Epoch 64 - D Loss: -0.0108, G Loss: 2.7200\n",
      "Mean L1 Loss: 2.184707, Mean L2 Loss: 8.583825\n",
      "Epoch 65, Iter 2550, D Loss: -0.0080, G Loss: 2.6989, L1: 2.1847, L2: 8.5838\n",
      "Epoch 65 - D Loss: -0.0096, G Loss: 2.7005\n",
      "Mean L1 Loss: 2.221379, Mean L2 Loss: 8.911975\n",
      "Epoch 66, Iter 2600, D Loss: -0.0092, G Loss: 2.6952, L1: 2.2214, L2: 8.9120\n",
      "Epoch 66 - D Loss: -0.0092, G Loss: 2.7127\n",
      "Mean L1 Loss: 2.213609, Mean L2 Loss: 8.810812\n",
      "Epoch 67, Iter 2650, D Loss: -0.0121, G Loss: 2.7270, L1: 2.2136, L2: 8.8108\n",
      "Epoch 67 - D Loss: -0.0122, G Loss: 2.7320\n",
      "Epoch 68 - D Loss: -0.0083, G Loss: 2.7500\n",
      "Mean L1 Loss: 2.239528, Mean L2 Loss: 8.944032\n",
      "Epoch 69, Iter 2700, D Loss: -0.0016, G Loss: 2.7161, L1: 2.2395, L2: 8.9440\n",
      "Epoch 69 - D Loss: -0.0052, G Loss: 2.7140\n",
      "Mean L1 Loss: 2.248345, Mean L2 Loss: 9.109171\n",
      "Epoch 70, Iter 2750, D Loss: -0.0069, G Loss: 2.7133, L1: 2.2483, L2: 9.1092\n",
      "Epoch 70 - D Loss: -0.0071, G Loss: 2.7248\n",
      "Mean L1 Loss: 2.276882, Mean L2 Loss: 9.303261\n",
      "Epoch 71, Iter 2800, D Loss: -0.0079, G Loss: 2.7282, L1: 2.2769, L2: 9.3033\n",
      "Epoch 71 - D Loss: -0.0072, G Loss: 2.7289\n",
      "Epoch 72 - D Loss: -0.0071, G Loss: 2.7208\n",
      "Mean L1 Loss: 2.232762, Mean L2 Loss: 9.031297\n",
      "Epoch 73, Iter 2850, D Loss: -0.0051, G Loss: 2.7085, L1: 2.2328, L2: 9.0313\n",
      "Epoch 73 - D Loss: -0.0063, G Loss: 2.7242\n",
      "Mean L1 Loss: 2.251439, Mean L2 Loss: 9.119081\n",
      "Epoch 74, Iter 2900, D Loss: -0.0041, G Loss: 2.6713, L1: 2.2514, L2: 9.1191\n",
      "Epoch 74 - D Loss: -0.0045, G Loss: 2.7022\n",
      "Mean L1 Loss: 2.254668, Mean L2 Loss: 9.120455\n",
      "Epoch 75, Iter 2950, D Loss: -0.0038, G Loss: 2.7063, L1: 2.2547, L2: 9.1205\n",
      "Epoch 75 - D Loss: -0.0038, G Loss: 2.7128\n",
      "Mean L1 Loss: 2.251839, Mean L2 Loss: 9.119552\n",
      "Epoch 76, Iter 3000, D Loss: -0.0062, G Loss: 2.7227, L1: 2.2518, L2: 9.1196\n",
      "Epoch 76 - D Loss: -0.0064, G Loss: 2.7228\n",
      "Epoch 77 - D Loss: -0.0044, G Loss: 2.7251\n",
      "Mean L1 Loss: 2.258965, Mean L2 Loss: 9.192189\n",
      "Epoch 78, Iter 3050, D Loss: -0.0011, G Loss: 2.7433, L1: 2.2590, L2: 9.1922\n",
      "Epoch 78 - D Loss: -0.0034, G Loss: 2.7174\n",
      "Mean L1 Loss: 2.292798, Mean L2 Loss: 9.323719\n",
      "Epoch 79, Iter 3100, D Loss: -0.0007, G Loss: 2.6856, L1: 2.2928, L2: 9.3237\n",
      "Epoch 79 - D Loss: -0.0013, G Loss: 2.7164\n",
      "Mean L1 Loss: 2.292295, Mean L2 Loss: 9.427954\n",
      "Epoch 80, Iter 3150, D Loss: -0.0039, G Loss: 2.7069, L1: 2.2923, L2: 9.4280\n",
      "Epoch 80 - D Loss: -0.0040, G Loss: 2.7098\n",
      "Epoch 81 - D Loss: -0.0039, G Loss: 2.7349\n",
      "Mean L1 Loss: 2.287653, Mean L2 Loss: 9.443571\n",
      "Epoch 82, Iter 3200, D Loss: 0.0041, G Loss: 2.6298, L1: 2.2877, L2: 9.4436\n",
      "Epoch 82 - D Loss: 0.0002, G Loss: 2.7430\n",
      "Mean L1 Loss: 2.292838, Mean L2 Loss: 9.491022\n",
      "Epoch 83, Iter 3250, D Loss: -0.0014, G Loss: 2.7677, L1: 2.2928, L2: 9.4910\n",
      "Epoch 83 - D Loss: -0.0036, G Loss: 2.7594\n",
      "Mean L1 Loss: 2.355237, Mean L2 Loss: 9.681334\n",
      "Epoch 84, Iter 3300, D Loss: -0.0029, G Loss: 2.7592, L1: 2.3552, L2: 9.6813\n",
      "Epoch 84 - D Loss: -0.0010, G Loss: 2.7699\n",
      "Mean L1 Loss: 2.299244, Mean L2 Loss: 9.478664\n",
      "Epoch 85, Iter 3350, D Loss: -0.0010, G Loss: 2.7612, L1: 2.2992, L2: 9.4787\n",
      "Epoch 85 - D Loss: -0.0018, G Loss: 2.7594\n",
      "Epoch 86 - D Loss: -0.0021, G Loss: 2.7434\n",
      "Mean L1 Loss: 2.300430, Mean L2 Loss: 9.551039\n",
      "Epoch 87, Iter 3400, D Loss: 0.0047, G Loss: 2.7340, L1: 2.3004, L2: 9.5510\n",
      "Epoch 87 - D Loss: -0.0007, G Loss: 2.7627\n",
      "Mean L1 Loss: 2.307047, Mean L2 Loss: 9.414277\n",
      "Epoch 88, Iter 3450, D Loss: -0.0013, G Loss: 2.7300, L1: 2.3070, L2: 9.4143\n",
      "Epoch 88 - D Loss: -0.0004, G Loss: 2.7465\n",
      "Mean L1 Loss: 2.296639, Mean L2 Loss: 9.546471\n",
      "Epoch 89, Iter 3500, D Loss: 0.0024, G Loss: 2.7706, L1: 2.2966, L2: 9.5465\n",
      "Epoch 89 - D Loss: 0.0009, G Loss: 2.7737\n",
      "Epoch 90 - D Loss: -0.0021, G Loss: 2.7570\n",
      "Mean L1 Loss: 2.320750, Mean L2 Loss: 9.566336\n",
      "Epoch 91, Iter 3550, D Loss: -0.0030, G Loss: 2.7283, L1: 2.3207, L2: 9.5663\n",
      "Epoch 91 - D Loss: -0.0008, G Loss: 2.7708\n",
      "Mean L1 Loss: 2.315255, Mean L2 Loss: 9.570682\n",
      "Epoch 92, Iter 3600, D Loss: -0.0002, G Loss: 2.7427, L1: 2.3153, L2: 9.5707\n",
      "Epoch 92 - D Loss: 0.0013, G Loss: 2.7725\n",
      "Mean L1 Loss: 2.332659, Mean L2 Loss: 9.594435\n",
      "Epoch 93, Iter 3650, D Loss: -0.0001, G Loss: 2.7484, L1: 2.3327, L2: 9.5944\n",
      "Epoch 93 - D Loss: 0.0006, G Loss: 2.7583\n",
      "Mean L1 Loss: 2.347676, Mean L2 Loss: 9.738916\n",
      "Epoch 94, Iter 3700, D Loss: -0.0001, G Loss: 2.7739, L1: 2.3477, L2: 9.7389\n",
      "Epoch 94 - D Loss: 0.0007, G Loss: 2.7760\n",
      "Epoch 95 - D Loss: 0.0005, G Loss: 2.7795\n",
      "Mean L1 Loss: 2.346395, Mean L2 Loss: 9.831549\n",
      "Epoch 96, Iter 3750, D Loss: -0.0005, G Loss: 2.8029, L1: 2.3464, L2: 9.8315\n",
      "Epoch 96 - D Loss: 0.0007, G Loss: 2.7969\n",
      "Mean L1 Loss: 2.343455, Mean L2 Loss: 9.770018\n",
      "Epoch 97, Iter 3800, D Loss: 0.0078, G Loss: 2.7958, L1: 2.3435, L2: 9.7700\n",
      "Epoch 97 - D Loss: 0.0029, G Loss: 2.7830\n",
      "Mean L1 Loss: 2.344367, Mean L2 Loss: 9.824545\n",
      "Epoch 98, Iter 3850, D Loss: 0.0018, G Loss: 2.7757, L1: 2.3444, L2: 9.8245\n",
      "Epoch 98 - D Loss: 0.0009, G Loss: 2.7773\n",
      "Mean L1 Loss: 2.326445, Mean L2 Loss: 9.710871\n",
      "Epoch 99, Iter 3900, D Loss: 0.0047, G Loss: 2.8459, L1: 2.3264, L2: 9.7109\n",
      "Epoch 99 - D Loss: 0.0047, G Loss: 2.8459\n"
     ]
    }
   ],
   "source": [
    "# Training\n",
    "trained_G, trained_D = train_WGR_fnn(D=D_net, G=G_net, D_solver=D_solver, G_solver=G_solver, \n",
    "                                     loader_train = loader_train, loader_val=loader_val, noise_dim=args.noise_dim, \n",
    "                                     Xdim=args.Xdim, Ydim=args.Ydim, batch_size=args.train_batch, \n",
    "                                     save_path='./', device='cpu', num_epochs=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "daf00ecd-57df-4b58-841e-932233afcf78",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: M1, Univariate, Ydim: 1, J_t_size: 50\n",
      "L1 Loss: tensor([1.6839])\n",
      "L2 Loss: tensor([5.3885])\n",
      "MSE Mean: tensor([2.5918])\n",
      "MSE SD: tensor([0.2850])\n"
     ]
    }
   ],
   "source": [
    "# Calculate the L1 and L2 error, MSE of conditional mean and conditional standard deviation on the test data  \n",
    "test_G_mean_sd = L1L2_MSE_mean_sd_G(G = trained_G,  test_size = args.test, noise_dim=args.noise_dim, Xdim=args.Xdim,\n",
    "                                    batch_size=args.test_batch,  model_type=args.model, loader_dataset = loader_test )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a53a40ac-b651-443f-8476-bbc9949dbeca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Q_5: 2.9589, Q_25: 2.6305, Q_50: 2.6051, Q_75: 2.8051, Q_95: 3.6236\n"
     ]
    }
   ],
   "source": [
    "# Calculate the MSE of conditional quantiles at different levels.\n",
    "test_G_quantile = MSE_quantile_G_uniY(G = trained_G, loader_dataset = loader_test , noise_dim=args.noise_dim, Xdim=args.Xdim,\n",
    "                                      test_size = args.test,  batch_size=args.test_batch, model_type=args.model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7cc16ad8-4d13-4b6f-ac05-8c45ab75c6e7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac4f942f-a600-4056-b8c8-ca9fdcce00b1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "025bf56f-0d8f-4817-b816-6f1d2837dc76",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
